In 2004, engineers at Google introduced a new paradigm for large-scale parallel data processing known as MapReduce. One key aspect of MapReduce is that it makes programming such tasks on large-scale clusters easy for developers; instead of worrying about how to manage parallelism, handle machine crashes, and many other complexities common within clusters of machines, the developer can instead just focus on writing little bits of code (described below) and the infrastructure handles the rest.
This is a simplified MapReduce for a single machine 
